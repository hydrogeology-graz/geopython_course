{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "706dd19e",
   "metadata": {},
   "source": [
    "<img src=\"https://static.uni-graz.at/fileadmin/nawi-institute/Erdwissenschaften/NawiGrazGeozentrum_Small.png\" align=\"right\" width=200>\n",
    "\n",
    "# Notebook 5: Data Analysis with Pandas\n",
    "\n",
    "*Developed by Raoul Collenteur, Institute of Earth Sciences, NAWI Graz Geocenter, University of Graz.*\n",
    "\n",
    "In this Notebook we will look into data analysis using Pandas. Pandas (http://pandas.pydata.org) is one of the most popular packages in Python and is used to analyse (big) data. With Pandas, analyzing big-data becomes much easier and faster. With more and more data being collected every day, data analysis becomes more a more important part of Earth Scientists' every day jobs.\n",
    "\n",
    "\n",
    "## Lecture content\n",
    "\n",
    "1. [Reading and writing CSV files](#1.-Reading-and-writing-CSV-files)\n",
    "2. [The Pandas DataFrame and indexing](#2.-The-Pandas-DataFrame-and-indexing)\n",
    "3. [Descriptive statistics](#3.-Descriptive-statistics)\n",
    "4. [Plotting data](#4.-Plotting-data)\n",
    "5. [Time series data](#5.-Time-series-data)\n",
    "6. [Answers to Exercises](#6.-Anwers-to-Exercises)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db192d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the python packages needed in this session\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "490d590d",
   "metadata": {},
   "source": [
    "## 1. Reading and writing CSV files\n",
    "In a previous lecture we learned how to use the `loadtxt` method from Numpy to load data from a text file. This method returns a Numpy array, which is particularly usefull when looking at numerical data (floats, integers). Often we also have other data types (e.g., strings, booleans) stored in a file, and it is better to put the data in another data format. Pandas provides a very strong data type to work with tabular data (Excel-like) in Python: the Pandas `DataFrame`.\n",
    "\n",
    "To load data from a file, like txt, csv,or xlsx, we can use Pandas `read_csv` method. This is a very usefull method to load tabular data from text files. In the code-block below, we use `delimiter=\";\"` to indicate that the data is separated by a semi-colon, and `index_col=0` to use the first column as the index column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79faedad",
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = \"Size-Slope-Data-Points.csv\"\n",
    "\n",
    "df = pd.read_csv(fname, delimiter=\";\", index_col=0)\n",
    "\n",
    "print(type(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ff3983e",
   "metadata": {},
   "source": [
    "The data is loaded into a Pandas `DataFrame`, a data structure that has all kinds of usefull functions attached to it. For example, to obtain a quick look at the data we may call the `head` function. This function prints the first 5 rows of the data for a quick view into the avaialble data (structure)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "225fd50e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b679cb84",
   "metadata": {},
   "source": [
    "If we want to write a `DataFrame` to file, we can use the `to_csv` method. The first argument of this method is the name (or path) of the file that is created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1f0d9ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"test_file.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97f005be",
   "metadata": {},
   "source": [
    "### Exercise 1\n",
    "\n",
    "In this exercise we want to read in only specific parts the data stored in the file `Size-Slope-Data-Points.csv`. Go to [the documentation](https://pandas.pydata.org/docs/user_guide/io.html#io-read-csv-table) of the `read_csv` method and read about the different input arguments.\n",
    "\n",
    "1. Read only the first 100 lines and use the columns \"Clast size ()\", and \"Slope (deg)\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07eedd94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Type your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d75ec1f",
   "metadata": {},
   "source": [
    "[Answer](#Answers-to-Exercises)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d0d9828",
   "metadata": {},
   "source": [
    "## 2. The Pandas DataFrame and indexing\n",
    "The Pandas DataFrame can be used to store 2D (tabular) data, similar to the data in a spreadsheet (e.g., Excel). Each column can have it's own data type (e.g., floats, ints, strings). A `DataFrame` has many functions connected the object that can be used to analyse the data. The functions range from descriptive statistics, to resampling, and plotting. If you want to learn more about the DataFrame object, check out [this documentation](https://pandas.pydata.org/docs/user_guide/dsintro.html#dataframe). \n",
    "\n",
    "Note that the first column is the `index` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dd270a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b77b4be",
   "metadata": {},
   "source": [
    "There are several option to access (a subset of) the data stored in a `DataFrame`. This can be a bit confusing in the beginning, but it is fairly similar to accessing data in Numpy `arrays`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7351db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To access a single columns, simply use the column name\n",
    "df[\"Type\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b653982f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2a44944",
   "metadata": {},
   "source": [
    "To get the unique values in the column \"Type\" we can use the function `unique()`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e31c4cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Type\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99f6fe12",
   "metadata": {},
   "source": [
    "### Accessing data using .loc and .iloc\n",
    "\n",
    "The recommended method to access that in a `DataFrame` is through the use of `.loc` and `.iloc`. The first method uses the data type of the columns, while the second uses integers to select data (exactly like Numpy). Let's have a look at some examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8d3055d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To select all rows, one column named \"Type\"\n",
    "df.loc[:, \"Type\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "333dd21b",
   "metadata": {},
   "source": [
    "or to use iloc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc704f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To select all rows, two column\n",
    "df.loc[:, [\"Type\", 'Slope (deg)']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eafa57c",
   "metadata": {},
   "source": [
    "`iloc` only uses integers, for example as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c93b414",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the first three rows from the first column (not the index)\n",
    "df.iloc[:3, 0:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a7cf4bb",
   "metadata": {},
   "source": [
    "### Selecting data with boolean indexers\n",
    "\n",
    "We may also use conditional statements to select specific parts of the data that agree with a certain condition. For example, let's imagine we want to select all the rows where the slope > 5 degrees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ef06f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df.loc[:, \"Slope (deg)\"] > 5, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04c90e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# These conditional statement can also be combined \n",
    "df.loc[(df.loc[:, \"Slope (deg)\"] > 5) & (df.loc[:, \"Clast size (mm)\"] > 5), :] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6c05669",
   "metadata": {},
   "source": [
    "### Creating Setting data\n",
    "\n",
    "Often we want create a new `DataFrame` and store some data in it. Here's how to create an empty DataFrame with index and columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b54b2bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame(index=[1,2,3], columns=[\"A\", \"B\"])\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e92c3626",
   "metadata": {},
   "source": [
    "Say we want to set the value for row 3 and column B to 6.0. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d29f736e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[3, \"B\"] = 6.0\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcf5386f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[:, \"A\"] = [9, 4.5, 3]\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "207a4277",
   "metadata": {},
   "source": [
    "The above DataFrame still has NaN-values (Not a Number) left. Pandas provides a convenient method to replace all NaN-values in a DataFrame at once: `fillna`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f2d0ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.fillna(0)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03ae99b8",
   "metadata": {},
   "source": [
    "What happened above? The method `fillna` actually return a copy of the data, and not the DataFrame itself. That means to original data is not changed. Therefore we need to store the data again as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74d1f28c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.fillna(0)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45623b6f",
   "metadata": {},
   "source": [
    "### Exercise 2\n",
    "\n",
    "1. Load the data from `Size-Slope-Data-Points.csv` into a DataFrame\n",
    "2. print the number of rows with the type \"Unknowns\".\n",
    "3. Replace all instances with the value \"6\" in the column \"Type\" with \"Unknown\".\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8acc5424",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Type your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fdde43d",
   "metadata": {},
   "source": [
    "[Answer](#Answers-to-Exercises)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0347333d",
   "metadata": {},
   "source": [
    "## 3. Descriptive statistics\n",
    "\n",
    "Descriptive statistics can be used to describe and summarize the data. Common questions are what the mean and standard deviation of a collection of data are. Pandas provides some basic utility functions to describe and summarize your data, usefull when reporting on your data in a report. The `describe` method provides a nice summary table of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ebc2246",
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = \"Size-Slope-Data-Points.csv\"\n",
    "df = pd.read_csv(fname, delimiter=\";\", index_col=0)\n",
    "\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5869b0ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.quantile(0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f46a3f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cbf5172",
   "metadata": {},
   "source": [
    "### Exercise 3\n",
    "Report the standard deviation, kurtosis and the median of the \"Slope (deg)\", but only for rows where the clkast size exceeds 50 mm. Do not use the `df.describe()` method but use the individual functions! Round all reported values to 2 decimals. You may need to look at the Pandas docs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2b4b08a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Type your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "035748af",
   "metadata": {},
   "source": [
    "[Answer](#Answers-to-Exercises)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34791549",
   "metadata": {},
   "source": [
    "## 4. Plotting data\n",
    "\n",
    "Data visualization is an important part of data analysis, and is also supported by Pandas. Visualizing your data is often the quickest and easiest method to analyse your data and obtain a better understanding. See [the Documentation](https://pandas.pydata.org/docs/reference/frame.html#plotting) for all the plotting possibilities. Pandas plotting is directly built upon Matplotlib, so many of the commands we learned in the Matplotlib lecture can be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12fb9c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = \"Size-Slope-Data-Points.csv\"\n",
    "df = pd.read_csv(fname, delimiter=\";\", index_col=0)\n",
    "\n",
    "df.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0b6c310",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.plot(subplots=True, figsize=(10,4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a0a75ae",
   "metadata": {},
   "source": [
    "making histograms to look at the distribution of your data is very easy as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01d193ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = df.loc[:, \"Slope (tan)\"].plot.hist(bins=20)\n",
    "ax.set_title(\"histogram\")\n",
    "ax.set_xlabel(\"Slope (tan)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a995de8",
   "metadata": {},
   "source": [
    "Often we want to look at the relationship between two variables (two columns). This can be done is follows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bfdd68b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.plot(x='Slope (deg)', y=\"Clast size ()\", linestyle=\" \", marker=\".\")\n",
    "plt.ylabel(\"Clast size (mm)\")\n",
    "plt.xlabel(\"Slope (deg)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f358c9db",
   "metadata": {},
   "source": [
    "### Exercise 4\n",
    "\n",
    "In this exercise we will use the `boxplot` method to create three boxplots for three columns, grouped by the \"Type\".\n",
    "\n",
    "1. Read the [documentation on boxplot](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.boxplot.html#pandas.DataFrame.boxplot)\n",
    "2. Select all the data for the columns \"Type\", \"Slope (tan)\", \"Clast size ()\", \"Slope (deg)\"\n",
    "3. Create a boxplots, grouped by the \"Type\" column.\n",
    "4. apply `plt.tight_layout`\n",
    "5. Store the figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f105b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Type your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76f5dfd6",
   "metadata": {},
   "source": [
    "[Answer](#Answers-to-Exercises)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7ed6e29",
   "metadata": {},
   "source": [
    "## 5. Time series data\n",
    "\n",
    "Pandas is perhaps most known for its ability to deal with time series data. Time series data is data that is collected over time, and has both information on the variable of interest and the time a measurement was performed. Often this data is stored in tables, and the index is used to store the date and time (datetime) of the measurement. Pandas has a dedicated data structure for 1 dimensional time series data: the Pandas `Series`. If you want to learn more about the TimeSeries object, check out [this documentation](https://pandas.pydata.org/docs/user_guide/dsintro.html#series). \n",
    "\n",
    "Here we look at groundwater level time series (also called \"heads\") from a measurement station in Wagna, south of Graz. The data is available here http://doi.org/10.5281/zenodo.4548801, but is also provided with this notebook (head_wagna.csv). Lets load the time series and have a look what Pandas can do with time series data!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5b9abf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = \"head_wagna.csv\"\n",
    "ts = pd.read_csv(fname, index_col=0, infer_datetime_format=True, parse_dates=True, skiprows=1, squeeze=True)\n",
    "type(ts)\n",
    "ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e98b5d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cad1b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(ts.index))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f63a299",
   "metadata": {},
   "source": [
    "This time series has very similar capabilities as the pandas `DataFrame` object we looked ast before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c36d270d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts.plot(figsize=(10,2), color=\"k\");\n",
    "plt.ylabel(\"Head [m]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65af35d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58c1e4f9",
   "metadata": {},
   "source": [
    "### Selecting data by datetime\n",
    "\n",
    "To select data based on a certain range of dates, we can used strings with the date. The string format is always \"YYYY-MM-DD\", where YYYY is the year, MM the month and DD the day. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d7e7e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts.loc[\"2014\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29bdd03a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts.loc[\"2014-06\":\"2014-07\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e64d3d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts.loc[\"2014-06-15\":\"2014-07-01\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc555f52",
   "metadata": {},
   "source": [
    "### Resampling time series\n",
    "\n",
    "Another usefull option in Pandas is to resample time series data to different frequencies ([see Docs on resample here](https://pandas.pydata.org/docs/reference/resampling.html)). For example, imagine we have daily observations of the groundwater levels, but want to compute the average groundwater level for each year in the time series. We then simply `resample` the time series to annual values (\"A\") and compute the mean. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52a0ef84",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts1 = ts.resample(\"A\").mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d207dd85",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts.plot(figsize=(10,2))\n",
    "ts1.plot()\n",
    "plt.legend([\"Original\", \"Annual Mean\"], ncol=2)\n",
    "plt.ylabel(\"Head [m]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0309aa78",
   "metadata": {},
   "source": [
    "### Exercise 5\n",
    "\n",
    "1. Load the rainfall time series from file `rain_wagna.csv` into a Pandas `Series`.\n",
    "2. Create a figure with 2 subplots below each other with sharex x-axes.\n",
    "3. Select only the years 2013 and 2014 from the time series\n",
    "4. Plot the monthly sums as a bar plot in the top plot.\n",
    "5. Plot the cumulative sum (lookup the `cumsum` method) in the bottom plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "281109e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Type your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46d894f5",
   "metadata": {},
   "source": [
    "[Answer](#Answers-to-Exercises)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8daba883",
   "metadata": {},
   "source": [
    "## Extra: Going Spatial with GeoPandas\n",
    "\n",
    "There is an exciting Project built upon Pandas, named GeoPandas, that is particularly interesting for geoscientists. The GeoPandas package can be used to perform GIS analyses through Python, to analyse spatial data with little effort. Check out the Documentation and examples on their website https://geopandas.org !\n",
    "\n",
    "A short example is shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae440861",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas\n",
    "\n",
    "path_to_data = geopandas.datasets.get_path(\"nybb\")\n",
    "gdf = geopandas.read_file(path_to_data)\n",
    "\n",
    "gdf.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b07480aa",
   "metadata": {},
   "source": [
    "## Answers to Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e9afb28",
   "metadata": {},
   "source": [
    "### Exercise 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b5ae821",
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = \"Size-Slope-Data-Points.csv\"\n",
    "\n",
    "df = pd.read_csv(fname, delimiter=\";\", index_col=0, usecols=[\"Type\", \"Clast size ()\", \"Slope (deg)\"], nrows=100)\n",
    "# df = pd.read_csv(fname, delimiter=\";\", index_col=0, usecols=[0, 4, 5], nrows=100)  # Alternatively\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90a4c648",
   "metadata": {},
   "source": [
    "### Exercise 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fd02c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data \n",
    "fname = \"Size-Slope-Data-Points.csv\"\n",
    "df = pd.read_csv(fname, delimiter=\";\", index_col=0)\n",
    "\n",
    "# Replace data with\n",
    "df.loc[df.loc[:, \"Type\"] == \"6\", \"Type\"] = \"Unknown\"\n",
    "\n",
    "# Print number of items\n",
    "print(df.loc[df.loc[:, \"Type\"] == \"Unknown\", \"Type\"].index.size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e920426",
   "metadata": {},
   "source": [
    "### Exercise 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25bf82ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data \n",
    "fname = \"Size-Slope-Data-Points.csv\"\n",
    "df = pd.read_csv(fname, delimiter=\";\", index_col=0)\n",
    "\n",
    "df1 = df.loc[df.loc[:, \"Clast size (mm)\"] > 50, \"Slope (deg)\"]\n",
    "\n",
    "print(\"the standard deviations is\", df1.std().round(2))\n",
    "print(\"the kurtosis is\", df1.kurtosis().round(2))\n",
    "print(\"the median is\", df1.median().round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4be4133c",
   "metadata": {},
   "source": [
    "### Exercise 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d7e0ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data \n",
    "fname = \"Size-Slope-Data-Points.csv\"\n",
    "df = pd.read_csv(fname, delimiter=\";\", index_col=0)\n",
    "\n",
    "data = df.loc[:, [\"Type\", \"Slope (tan)\", \"Clast size ()\", \"Slope (deg)\"]]\n",
    "data.boxplot(by=\"Type\", layout=(1,3))\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"my_figure.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bc4a21a",
   "metadata": {},
   "source": [
    "### Exercise 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86b93bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1. Load the rainfall time series from file `rain_wagna.csv` into a Pandas `Series`.\n",
    "fname = \"rain_wagna.csv\"\n",
    "rain = pd.read_csv(fname, index_col=0, infer_datetime_format=True, parse_dates=True, skiprows=1, squeeze=True)\n",
    "\n",
    "#2. Create a figure with 2 subplots\n",
    "fig, [ax1, ax2] = plt.subplots(2, 1)\n",
    "\n",
    "#3. Select only the years 2013 and 2014 from the time series\n",
    "ts_sel = rain.loc[\"2013\":\"2014\"]\n",
    "\n",
    "#4. Plot the monthly sums in the left plot.\n",
    "ts_sel.resample(\"M\").sum().plot.bar(ax=ax1)\n",
    "\n",
    "#5. Plot the cumulative sum in the right plot\n",
    "ts_sel.cumsum().plot()\n",
    "\n",
    "#6. Dress up the plot \n",
    "ax1.set_ylabel(\"Monthly\\nrain [mm]\")\n",
    "ax2.set_ylabel(\"Cumulative\\nRain [mm]\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
