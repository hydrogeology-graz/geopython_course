{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://static.uni-graz.at/fileadmin/nawi-institute/Erdwissenschaften/NawiGrazGeozentrum_Small.png\" align=\"right\" width=200>\n",
    "\n",
    "# Notebook 6: Curve fitting with Scipy\n",
    "\n",
    "*Developed by Raoul Collenteur and Matevž Vremec University of Graz, 2021.*\n",
    "\n",
    "In this final Notebook we will learn about the [SciPy package](https://docs.scipy.org/doc/scipy/reference/tutorial/general.html), which is a collection of tools that are commonly used in scientific studies. The SciPy package is part of the Scipy Ecosystem, which also includes Numpy, Pandas and Matplotlib. Together, these four packages contain the most important methods for many exercises in science, mathematics and engineering. \n",
    "\n",
    "There are many different sub-packages in the SciPy package, and in this Notebook we will look into one of them: `scipy.optimize`. This is a package that contains algorithms to find 'optimal' parameter values by fitting a model to observed data, a common task in research.\n",
    "\n",
    "### Lecture content\n",
    "\n",
    "1. [Importing Scipy methods](#1-Importing-Scipy-methods)\n",
    "2. [Fitting a curve](#2-Fitting-a-curve)\n",
    "3. [Least Squares solutions](#3-Least-Squares-solutions)\n",
    "4. [Finding the least-squares solution](#4-Finding-the-least-squares-solution)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages here\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is curve fitting and why do we need it?\n",
    "\n",
    "In regression analysis, curve fitting is the process of constructing a curve (mathematical function) that has the best fit to a series of data points.\n",
    "\n",
    "For engineers, curve-fitting is a tool to understand the physical law driving the observations. The fitting parameters' values often represent measurable physical quantities (e.g., weight and volume have a linear relationship for a given material).\n",
    "\n",
    "In research, we often focus on getting the best quality fit. We then use the derived parameters to predict the future (sometimes with less emphasis on understanding the physical phenomena underlying the observations).\n",
    "\n",
    "<img src=\"https://s3.amazonaws.com/stackabuse/media/linear-regression-python-scikit-learn-1.png\" align=\"center\" width=400>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Importing Scipy methods\n",
    "The SciPy package is subdivided into multiple sub-packages and methods. It is common practice to import a single function from SciPy instead of importing the entire package. The following statement can be used to import the `curve_fit` function from the `optimize` package:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import curve_fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#curve_fit?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are many methods in the `optimize` package to find optimal parameters for a function and data, for example `minimize`, `curve_fit`. There are many differrent algorithms to find the optimal parameters for a problem, which is science on it's own. An overview of all methods available in Scipy can be found here: https://docs.scipy.org/doc/scipy/reference/optimize.html#module-scipy.optimize.\n",
    "\n",
    "## 2. Fitting a function to some data\n",
    "The first method we will look at is `curve_fit`, a easy-to-use method to fit a model to observed data. First, let's generate some synthetic data, for the following linear function:\n",
    "\n",
    "$$y = Ax + B$$\n",
    "\n",
    "Where $A$ and $B$ are model parameters. We will start by defining a function that calculates $y$ for different values of $x$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(x, p1, p2):\n",
    "    \"\"\"Method to calculate y = ax +b .\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    x: np.ndarray\n",
    "        Numpy array with the values for x.\n",
    "    p1: float\n",
    "        parameter a.\n",
    "    p2: float\n",
    "        parameter b.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    y: np.ndarray\n",
    "        computed values for y.\n",
    "    \n",
    "    \"\"\"\n",
    "    y = p1 * x + p2\n",
    "    return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the `model` defined in the previous code-block to calculate values for $y$, providing different parameters to the function. In the codeblock below, we use the method to generate synthetic values for $y$, before adding some random noise to the values using `numpy.random` sub-package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 100  # Number of points to calculate x for.\n",
    "p1_true = 0.5\n",
    "p2_true = 10\n",
    "\n",
    "x_data = np.linspace(0,10, n)\n",
    "y_true = model(x_data, p1_true, p2_true)\n",
    "y_data = y_true + np.random.rand(n) - 0.5  # Add some random noise\n",
    "\n",
    "# Plot the data \n",
    "plt.plot(x_data, y_true)\n",
    "plt.plot(x_data, y_data, marker=\".\", linestyle=\" \", color='k')\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"y\")\n",
    "plt.legend([\"True Y\", \"Measured Y\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having defined a method that returns the values for $y$, it is now easy to use `curve_fit` to fit the model to the noisy data. For this, we provide the `curve_fit` method with a function that returns the estimate of $y$ (`model` in this case) and the $x$ and observed $y$-data. The `curve_method` returns a tuple with two arrays: the optimal parameters and the covariance matrix. Here, we will only use the optimal parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run curve_fit\n",
    "result = curve_fit(model, xdata=x_data, ydata=y_data)\n",
    "\n",
    "# Print the result\n",
    "result[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The optimal parameters should be close to the original parameters that were used to generate the data, but not exactly the same because we added random noise. To visually check our result, we can simulate $y$ using the estimated parameters and plot the result as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the estimated parameters\n",
    "# e1 = result[0][0] \n",
    "# e2 = result[0][1]\n",
    "e1, e2 = result[0]\n",
    "y_sim = model(x_data, e1, e2)  # Use the model method to simulatev  using the estimated parameters\n",
    "\n",
    "plt.plot(x_data, y_true)\n",
    "plt.plot(x_data, y_data, color=\"k\", linestyle=\" \", marker=\".\")\n",
    "plt.plot(x_data, y_sim, color=\"r\", linestyle=\"--\")\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"y\")\n",
    "plt.legend([\"True\", \"Measured\", \"estimated\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1: fitting a polynomial\n",
    "In this exercise we will fit a polynomial of the following form to some data:\n",
    "\n",
    "$$y(x) = a_1 x^2 + a_2 x + a_3$$\n",
    "\n",
    "where $a1$, $a2$, and $a3$ are parameters that need to be calibrated. Perform the following tasks in Python:\n",
    "\n",
    "- Define a function `polynomial` that takes $x$, $a1$, $a2$, and $a3$ as input arguments, calculates $y$  and returns $y$.\n",
    "- define three variables: $a1=1.5$, $a2=-2.5$, and $a3=2.0$\n",
    "- Generate data with a little noise (already done) for the interval $-5 < x < 10$\n",
    "- use `curve_fit` to find the optimal parameters for $a1$, $a2$, and $a3$.\n",
    "- Plot the True $y$, Noisy $y$ and estimated $y$ against $x$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the function\n",
    "\n",
    "# Define the \"True\" parameters\n",
    "\n",
    "# Create arrays with x, y, and y+noise\n",
    "x = np.linspace(-5, 10)\n",
    "y_true = polynomial(x, a1, a2, a3)\n",
    "y_noise = y_true + 10 * (np.random.rand(len(y_true))-0.5)\n",
    "\n",
    "# Find the optimal parameters\n",
    "\n",
    "# Plot the results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Answer](#Exercise-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Least-Squares solutions\n",
    "To calibrate the model and estimate the optimal parameters, `curve_fit` internally minimizes the sum of squared residuals as an objective function:\n",
    "The following objective function:\n",
    "\n",
    "$$ S(\\beta) = \\sum_{i=1}^N (y_i-f(\\beta))^2$$\n",
    "\n",
    "where $\\beta$ is the parameter set, $y_i$ the observed value of $y$ at index $i$, and $f$ a function that simulates $y$. Finding the minimum value for $S$ means we obtain the so-called \"least-squares\" solution of the problem. The method `curve_fit` iteratively changes the values of the parameters and evaluates the effect of the change in parameters on the objective function $S$.\n",
    "\n",
    "### Exercise 2: Define a residual and objective fucntion\n",
    "In this exercise you will write two functions: the first calculating the residuals and the second calculating the values for the objective function $S$:\n",
    "\n",
    "1. Define a function named `residuals`, that takes in input argument `p`, which is an array of length 2. This function internally calls the `model` method defined in the code-block below and stores the result in a local variable `sim`. The function should then calculate (`sim-obs`)  and return the residuals.\n",
    "2. Define a function named `obj_func` that calculates the value of $S$, using the residuals function to calculate the residuals. The method should return the values of the objective function.\n",
    "3. Test the methods using the provided code, the residuals should be between the two red lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create x and y data\n",
    "x_data = np.linspace(0,10, n)\n",
    "y_true = model(x_data, p1_true, p2_true)\n",
    "obs = y_true + np.random.rand(n) - 0.5  # Add some random noise\n",
    "\n",
    "# define the model\n",
    "def model(x, p1, p2):\n",
    "    y = p1 * x + p2\n",
    "    return y\n",
    "\n",
    "# Define the residuals function here\n",
    "\n",
    "# Define the obj_func function here\n",
    "\n",
    "\n",
    "# Test the methods\n",
    "p = [0.5, 10]\n",
    "res = residuals(p)\n",
    "plt.plot(x_data, res)\n",
    "plt.title(\"S={:.2f}\".format(obj_func(p)))\n",
    "plt.axhline(0.5, c=\"r\")\n",
    "plt.axhline(-0.5, c=\"r\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Answer](#Exercise-2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Finding the least-squares solution\n",
    "The use of an objective function to estimate the parameters can have some benefits over using `curve_fit`, for example the possibility to define different objective functions. To find the minimum of a function, Scipy has the `minimize` method. [See the documenation here](https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.minimize.html#scipy.optimize.minimize). This method takes a function that returns the value of an objective function (a single value). \n",
    "\n",
    "**Other often used objective functions in geosciences ($s_i = f(\\beta)$):**\n",
    "\n",
    "*Bias*\n",
    "$$ Bias = \\frac{1}{N} \\sum_{i=1}^{N}(y_{i}-s_{i}) $$\n",
    "\n",
    "*Mean Squared Error*\n",
    "$$ MSE = \\frac{1}{N} \\sum_{i=1}^{N}(y_{i}-s_{i})^2 $$\n",
    "\n",
    "*Root Mean Squared Error*\n",
    "$$ RMSE = \\sqrt{\\frac{1}{N} \\sum_{i=1}^{N}(y_{i}-s_{i})^2} $$\n",
    "\n",
    "*Nash-Sutcliffe model efficinecy*\n",
    "$$ NSE = 1-\\frac{\\sum_{i=1}^{N}(y_{i}-s_{i})^2}{\\sum_{i=1}^{N}(y_{i}-\\bar{y})^2} $$\n",
    "\n",
    "*Correlation Coefficient*\n",
    "$$ r = \\frac{\\sum ^n _{i=1}(y_i - \\bar{y})(s_i - \\bar{s})}{\\sqrt{\\sum ^n _{i=1}(y_i - \\bar{y})^2} \\sqrt{\\sum ^n _{i=1}(s_i - \\bar{s})^2}} $$ \n",
    "\n",
    "*Coefficient of Determination*\n",
    "$$ r^2=(\\frac{\\sum ^n _{i=1}(y_i - \\bar{o})(y_i - \\bar{s})}{\\sqrt{\\sum ^n _{i=1}(y_i - \\bar{y})^2} \\sqrt{\\sum ^n _{i=1}(s_i - \\bar{s})^2}})^2 $$\n",
    "\n",
    "*Kling-Gupta Efficiency*\n",
    "\n",
    "### Exercise 3: import minimize from scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Scipy here\n",
    "from scipy.optimize import minimize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Answer](#Exercise-3)\n",
    "\n",
    "Now we define two new methods, a `linear_model` (similar to `model` earlier), and an objective function that calculates $S$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_model(p1, p2):\n",
    "    y = p1 * x + p2\n",
    "    return y\n",
    "\n",
    "def obj_func(p):\n",
    "    sim = linear_model(p[0], p[1])\n",
    "    res = sim - obs\n",
    "    S = sum(res**2)\n",
    "    return S"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To find the optimal parameters, we minimize the objective funnction using `minimize`. The `minimize` method returns an Python object, which is a collection of different variables. The following code block shows how to use the method to fit a model to some data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate some data\n",
    "x = np.linspace(0, 100)\n",
    "y_true = linear_model(5, 9)\n",
    "obs = y_true + 100*(np.random.rand(len(x)) - 0.5)  # Add some random noise\n",
    "\n",
    "# Run minimize\n",
    "p0 = np.array([3, 1])  # Initial guess for the parameters\n",
    "result = minimize(obj_func, p0)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x, obs, marker=\".\", linestyle=\" \", c=\"k\")\n",
    "plt.plot(x, y_true)\n",
    "plt.plot(x, linear_model(result.x[0], result.x[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, this method returns a little more information than the `curve_fit` method. The optimization is a success (`result.success`), a number of function evaluations (`result.nfev`) and the optimal parameters (`results.x`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimated parameters\n",
    "result.x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4: Check the value for the objective function\n",
    "One of the things reported by the `minimize` method is the values of the objective function: `result.fun`. Use the optimized parameters to calculate the value of the objective function and validate that this is similar to `result.fun`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Type your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Answer](#Exercise-3)\n",
    "\n",
    "## Additional reading:\n",
    "- scipy `curve_fit` docs: https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.curve_fit.html#scipy.optimize.curve_fit\n",
    "- scipy `minimize` docs: https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.minimize.html#scipy.optimize.minimize\n",
    "\n",
    "## Answers to Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the function\n",
    "def polynomial(x, a1, a2, a3):\n",
    "    y = a1 * x ** 2 + a2 * x + a3\n",
    "    return y\n",
    "\n",
    "# Define the \"True\" parameters\n",
    "a1 = 1.50\n",
    "a2 = -2.50\n",
    "a3 = 2.0\n",
    "\n",
    "# Create arrays with x, y, and y+noise\n",
    "x = np.linspace(-5, 10)\n",
    "y_true = polynomial(x, a1, a2, a3)\n",
    "y_noise = y_true + 10 * (np.random.rand(len(y_true))-0.5)\n",
    "\n",
    "# Find the optimal parameters\n",
    "result = curve_fit(polynomial, xdata=x, ydata=y_noise)\n",
    "e1,e2,e3 = result[0]\n",
    "\n",
    "# Plot the results\n",
    "plt.plot(x, y_true, linewidth=3)\n",
    "plt.plot(x, y_noise, marker=\".\", linestyle=\" \", color=\"k\")\n",
    "plt.plot(x, polynomial(x, e1, e2, e3), linestyle=\"--\", color=\"r\")\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"y\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create x and y data\n",
    "x_data = np.linspace(0,10, n)\n",
    "y_true = model(x_data, p1_true, p2_true)\n",
    "obs = y_true + np.random.rand(n) - 0.5  # Add some random noise, obs is now a global variable\n",
    "\n",
    "# define the model\n",
    "def model(x, p1, p2):\n",
    "    y = p1 * x + p2\n",
    "    return y\n",
    "\n",
    "# Define the residuals function here\n",
    "def residuals(p):\n",
    "    sim = model(x_data, p[0], p[1])\n",
    "    res = sim - obs  # This makes use of the global variable obs!\n",
    "    return res\n",
    "\n",
    "# Define the obj_func function here\n",
    "def obj_func(p):\n",
    "    res = residuals(p)\n",
    "    S = sum(res**2)\n",
    "    return S\n",
    "\n",
    "# Test the methods\n",
    "p = [0.5, 10]\n",
    "res = residuals(p)\n",
    "plt.plot(x_data, res)\n",
    "plt.title(\"S={:.2f}\".format(obj_func(p)))\n",
    "plt.axhline(0.5, c=\"r\")\n",
    "plt.axhline(-0.5, c=\"r\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = obj_func(result.x)\n",
    "print(s, result.fun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
